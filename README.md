# Documentaci√≥n T√©cnica - Proyecto Integrador

## Descripci√≥n General

Este documento recopila el desarrollo, las decisiones t√©cnicas y la justificaci√≥n de cada etapa del Proyecto Integrador de An√°lisis de Ventas.
El objetivo general es construir una soluci√≥n robusta y escalable para transformar datos transaccionales en informaci√≥n clave para la toma de decisiones estrat√©gicas en la empresa.

El proyecto se organiza en tres avances principales:

- Primer Avance: Modelado conceptual y dise√±o de la arquitectura de clases en Python**, representando las entidades principales del negocio (productos, empleados, ventas, clientes, etc.), aplicando principios de Programaci√≥n Orientada a Objetos (POO) y buenas pr√°cticas de dise√±o.

- Segundo Avance: Construcci√≥n y normalizaci√≥n del modelo relacional en MySQL, implementaci√≥n de mecanismos de carga y validaci√≥n de datos, y desarrollo de consultas SQL avanzadas utilizando CTEs y funciones de ventana para el an√°lisis de ventas.

- Tercer Avance: Implementaci√≥n de objetos SQL reutilizables (procedimientos almacenados y vistas), integraci√≥n entre Python y la base de datos, y automatizaci√≥n de reportes mediante m√©todos y patrones de dise√±o que facilitan la consulta y explotaci√≥n de los datos para distintos perfiles de usuario.

Cada secci√≥n documenta los pasos realizados, la justificaci√≥n de las elecciones t√©cnicas y la forma en que cada avance contribuye a una soluci√≥n integral de an√°lisis de ventas.


# **Primer Avance**

## Objetivo:

Reci√©n incorporado al equipo de datos, se te ha asignado la tarea de sentar las bases del sistema de an√°lisis de ventas que la direcci√≥n necesita. En esta etapa inicial, debes dise√±ar una arquitectura de clases en Python que represente fielmente las entidades clave del negocio, asegurando que el sistema sea s√≥lido desde sus cimientos.

Cada decisi√≥n estructural ser√° crucial para garantizar un sistema escalable, mantenible y alineado con los objetivos anal√≠ticos de la empresa.


## Entregables:

### Entregables realizados:

- [x] Preparaci√≥n del entorno y generaci√≥n del archivo requirements.txt
- [x] Creaci√≥n de estructura de carpetas y archivos
- [x] Carga de datos en MySQL
- [x] Creaci√≥n de clases por cada tabla y aplicaci√≥n de principios de POO
- [x] Creaci√≥n de prueba unitaria de testing


## Desarrollo:

### Carga de Datos en MySQL

* En el archivo sql/load_data.sql, est√° el script desarrollado para la carga de datos desde los archivos .csv proporcionados

**Justificaci√≥n T√©cnica**

Cree las tablas sin Foreign Key para una carga de datos limpia. Para la carga de cada uno de los archivos .csv utilice la funci√≥n** LOAD DATA INFILE **de mysql, aunque tiene la desventaja de que en la carga no se puede proporcionar una ruta relativa lo que hace dif√≠cil de migrar. 

Porque no eleg√≠ rutas relativas: Porque para utilizar LOAD DATA LOCAL INFILE, que permite el uso de rutas relativas, el script deb√≠a estar en donde guarda el SGBD MySQL (C:\ProgramData\MySQL\MySQL Server 8.0) y yo necesitaba que leyera de la carpeta en donde est√° el proyecto. 

Para evitar errores de importaci√≥n se agregaron al script las cl√°usulas FIELDS TERMINATED BY ',' 

```sql
  ENCLOSED BY '"'
  LINES TERMINATED BY '\n'
  IGNORE 1 LINES;
```
esta √∫ltima cl√°usula para evitar claves ingresar claves primarias duplicadas.


### Creaci√≥n de clases por cada tabla y aplicaci√≥n de principios de POO

* En la carpeta src/models se encuentran cargados los modelos de cada clase:
    - `Category`, `city`, `country`, `customer`, `employee`, `product` y `sale`	

**Justificaci√≥n t√©cnica**

Como en este punto del proyecto integrador no se ped√≠a la carga de las clases en el ORM, arm√© las mismas teniendo en cuenta los principios de abstracci√≥n y encapsulamiento, 


*  Cada atributo de la clase es privado y solo pueden ser accedidos a trav√©s de getter y setter apropiados, utilizando la anotaci√≥n `@property` para los getters y `@atributo.setter` para el seteo de un nuevo valor del atributo. Consider√© la agregaci√≥n de getter y setters solo algunos atributos por clase, de acuerdo a cuales podr√≠an ser modificados y accedidos.
* Tambi√©n cree funciones por cada clase, de acuerdo a la informaci√≥n que el cliente podr√≠a querer recuperar de las clases.
* Por ejemplo la funci√≥n `get_full_name()` en customer y employee para acceder al nombre, `apply_discount()` y `is_expired()` en product y calculate_final_price() en sales.


### Creaci√≥n de prueba unitaria de testing

* En la carpeta test cree dos test sobre product:
    - test_apply_discount() y test_set_negative_price() sobre funciones que cree sobre la tabla products.

**Justificaci√≥n t√©cnica**

Cree pruebas b√°sicas para Product, con la idea de agregar m√°s pruebas en una pr√≥xima iteraci√≥n.

# **Segundo Avance**

## Objetivo

Con la base del sistema ya implementada, es momento de llevar la soluci√≥n a un nuevo nivel de calidad y sostenibilidad. Se debe trabajar sobre la modularizaci√≥n del c√≥digo y la incorporaci√≥n de patrones de dise√±o que favorezcan la escalabilidad.

Paralelamente, la empresa necesita empezar a responder preguntas clave sobre el comportamiento de ventas, por lo que se debe construir consultas SQL avanzadas que permitan transformar grandes vol√∫menes de datos en informaci√≥n clara y √∫til para la toma de decisiones estrat√©gicas.


## Entregables:

### Entregables realizados:

**Conexi√≥n a la Base de datos**

- [x] Crea una clase para conectarse a MySQL usando SQLAlchemy.
- [x] Aplica el patr√≥n Singleton para que la conexi√≥n sea √∫nica

**Dise√±o e implementaci√≥n**

- [x] Elige e implementa patrones de dise√±o relevantes
- [x] Justifica la elecci√≥n de cada patr√≥n ¬øQue problema resuelve en este caso?

**Consultas desde Python**

- [x] Agrega un m√©todo en la clase de conexi√≥n que permita ejecutar consultas SQL simples
- [x] Formatea los resultados como DataFrames de Pandas

**Pruebas unitarias**

- [x] Implementa al menos una prueba unitaria con pytest enfocada en los patrones de dise√±o

**Seguridad de credenciales**

- [x] Guarda Credenciales de la base en un archivo .env
- [x] Aseg√∫rate de no exponer credenciales en el c√≥digo
- [x] Agrega .env al .gitignore

**Integraci√≥n final**

Crea un Jupyter Notebook donde se visualice:

- [x] Conexi√≥n exitosa a la base
- [x] Resultados de las queries
- [x] Uso de los patrones de dise√±o
- [x] Ejecuci√≥n de pruebas unitarias
- [x] Sube todo al repo


## Desarrollo

### Conexi√≥n a la Base de datos

#### Clase de Conexi√≥n a MySQL usando SQLAlchemy

Para la conexi√≥n al motor de base de datos MySQL utilic√© una clase espec√≠fica: DBConnection ubicada en el archivo database.py. 

Como requisito del avance implement√© el patr√≥n singleton, para asegurar que la conexi√≥n sea √∫nica y controlada desde cualquier parte del sistema.

**Implementaci√≥n del patr√≥n Singleton:**
```python
    def __new__(cls):
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                try:
                    cls._instance.engine = create_engine(DATABASE_URL, echo=False)
                    cls._instance.Session = scoped_session(
                        sessionmaker(bind=cls._instance.engine)
                    )
                except Exception as e:
                    raise RuntimeError(f"Error al conectar a la base de datos: {str(e)}")
            return cls._instance
```


**Justificaci√≥n t√©cnica**

El patr√≥n singleton se implementa en el m√©todo `__new__` que es el que crea el objeto. Se chequea si ya existe una instancia (_instance), sino la crea. Si existe retorna la misma.

Adem√°s de la utilizaci√≥n del patr√≥n singleton, utilic√© una scoped_session, que administra autom√°ticamente una sesi√≥n por hilo de ejecuci√≥n y siempre usa la misma gracias al patr√≥n Singleton. Esto evita problemas de concurrencia, especialmente si en el futuro hay varios kernels o instancias ejecut√°ndose en paralelo (por ejemplo, en Jupyter Notebook o desde la consola).

Si bien el entorno principal de trabajo para este proyecto no est√° pensado para ejecutarse en m√∫ltiples hilos de ejecuci√≥n, el uso de scoped_session es est√° pensado para el crecimiento del proyecto, y garantiza que el c√≥digo se mantenga seguro, escalable y preparado para cualquier escenario de ejecuci√≥n, evitando posibles errores.


### Dise√±o de implementaci√≥n de patrones de dise√±o

En el apartado anterior ya pudimos ver la implementaci√≥n del Singleton. Adem√°s implement√© el patr√≥n Factory, Strategy y Builder.

Teniendo en cuenta lo solicitado por la empresa: "***la empresa necesita empezar a responder preguntas clave sobre el comportamiento de ventas, por lo que deber√°s construir consultas SQL avanzadas que permitan transformar grandes vol√∫menes de datos en informaci√≥n clara y √∫til para la toma de decisiones estrat√©gicas.***"

Comenc√© a dise√±ar informes que ofrezcan informaci√≥n sobre los vendedores para facilitar la visualizaci√≥n y el an√°lisis de datos relevantes (por ejemplo, ventas totales por empleado, productos m√°s vendidos, comparativas de desempe√±o, etc.), e informaci√≥n de compradores para ser implementadas a futuro.


### Patr√≥n Factory:

**Interfaz com√∫n:**

Definimos en cada implementaci√≥n un m√©todo est√°tico `from_series(serie: pd.Series)` que recibe una fila de dataframe y devuelve una instancia de la clase creada.


```python
class BaseFactory(ABC):
    @abstractmethod
    def from_series(self, serie: pd.Series):
        pass
```

**Implementaciones concretas:**

**SalesSummary:**

```python
class SalesSummary:
    @staticmethod
    def from_series(serie: pd.Series) -> "SalesSummary":
        return SalesSummary(
            sale_id       = serie["SalesID"],
            product_id    = serie["ProductID"],
            product_name  = serie["ProductName"],
            quantity      = serie["Quantity"],
            total_price   = serie["TotalPrice"],
            customer_id   = serie["CustomerID"],
            customer_name = serie["CustomerName"],
            employee_id   = serie["EmployeeID"],
            employee_name = serie["EmployeeName"],
        )
```

Esta clase agrupa datos de las tablas `Sales`, `Products`, `Customers` y `Employees`.

**CustomerLocationInfo:**

```python
class CustomerLocationInfo:
    @staticmethod
    def from_series(serie: pd.Series) -> "CustomerLocationInfo":
        return CustomerLocationInfo(
            customer_id = serie["CustomerID"],
            full_name   = serie["CustomerName"],
            address     = serie["Address"],
            city        = serie["CityName"],
            country     = serie["CountryName"],
        )
```

Esta clase agrupa datos de las tablas `Customers` + `Cities` + `Countries` en un s√≥lo objeto.

**Flujo de Uso:**

1. Ejecutar una consulta SQL con los campos necesarios para volcarlos a una de estas clases y transformarla en DataFrame.
2. Convertir cada fila en una clase determinada con el m√©todo `from_series`:

    ```python
    sales: List[SalesSummary] = [
        SalesSummary.from_series(row)
        for _, row in df_sales.iterrows()
    ]
    ```

3. Ya tenemos una lista de objetos SalesSummary con todos los campos renombrados y tipados, lista para:
    1. Validaciones de negocio
    2. Serializaci√≥n a JSON
    3. Env√≠o a un frontend
    4. O cualquier otra l√≥gica sin depender del DataFrame original

**Justificaci√≥n**

* Desacoplamiento: separa la lectura (SQL/CSV) de la creaci√≥n de objetos de dominio.
* Reutilizaci√≥n: cada clase de dominio encapsula su propia l√≥gica de mapeo.
* Flexibilidad: estas clases no est√°n ligadas al ORM, as√≠ pueden extenderse o combinarse sin tocar las entidades de la base.
* Preparaci√≥n para APIs: las clases se serializan ‚Äúlimpias‚Äù a JSON, exponiendo solo los campos necesarios.
* Nota: El prop√≥sito de estas clases no es persistir datos (lo hace el ORM), sino transportar datos preprocesados hacia capas de presentaci√≥n, reportes o clientes externos.

**Decisi√≥n t√©cnica:**

Esto favorece el principio abierto/cerrado (OCP), permitiendo agregar nuevas funcionalidades sin modificar el c√≥digo existente, y centraliza la l√≥gica de instanciaci√≥n, lo que reduce errores y facilita el mantenimiento.


### Patr√≥n Strategy

El patr√≥n strategy nos permite plantear m√∫ltiples estrategias que comparten una base com√∫n y que pueden adaptarse en base a diferentes casos.

**Interfaz com√∫n**

Definimos una clase abstracta `ReportStrategy` que obliga a todas las estrategias a implementar un m√©todo √∫nico:

```python
class ReportStrategy(ABC):
    @abstractmethod
    def generate_report(self, data: pd.DataFrame, key, ascending: bool) -> pd.DataFrame:
        pass
```

**Implementaciones concretas:**

1. **TotalSalesByEmployee:**

    Esta clase genera un informe de ventas por cada vendedor, mostrando por cada uno el total de ventas
    ```python
    class TotalSalesByEmployee(ReportStrategy):
        def generate_report(self, df, key, ascending=True):
            ventas = df.groupby("EmployeeID")[["TotalPrice"]].sum()
            nombres = df[["EmployeeID", "EmployeeName"]].drop_duplicates(
                subset="EmployeeID"
            )
            resultado = ventas.merge(nombres, on="EmployeeID", how="left")
            resultado = resultado[["EmployeeID", "EmployeeName", "TotalPrice"]]
            resultado.sort_values(key, ascending=ascending, inplace=True)
            resultado.columns = ["IDVendedor", "Nombre Apellido Vendedor", "TotalVentas"]
            return resultado

    ```

2. **AverageSalesByEmployee:**

    Esta clase genera un informe de ventas por vendedor, mostrando por cada uno el promedio de ventas.

    ```python
        class AverageSalesByEmployee(ReportStrategy):
            def generate_report(self, df, key, ascending=True):
                ventas = df.groupby("EmployeeID")[["TotalPrice"]].mean().round(2)
                nombres = df[["EmployeeID", "EmployeeName"]].drop_duplicates(
                    subset="EmployeeID"
                )
                resultado = ventas.merge(nombres, on="EmployeeID", how="left")

                resultado = resultado[["EmployeeID", "EmployeeName", "TotalPrice"]]
                resultado.sort_values(key, ascending=ascending, inplace=True)
                resultado.columns = [
                    "IDVendedor",
                    "Nombre Apellido Vendedor",
                    "Promedio de ventas",
                ]
            return resultado
    ```
3. **ProductSalesByEmployee:**

    Esta clase genera un informe de ventas por empleado, mostrando por cada uno la cantidad de productos vendidos.

    ```python
        class ProductSalesByEmployee(ReportStrategy):
        def generate_report(self, df, key, ascending=True):
                ventas = df.groupby("EmployeeID")[["ProductID"]].count()
                nombres = df[["EmployeeID", "EmployeeName"]].drop_duplicates(
                    subset="EmployeeID"
                )
                resultado = ventas.merge(nombres, on="EmployeeID", how="left")

                resultado = resultado[["EmployeeID", "EmployeeName", "ProductID"]]
                resultado.sort_values(key, ascending=ascending, inplace=True)
                resultado.columns = [
                    "IDVendedor",
                    "Nombre Apellido Vendedor",
                    "Cantidad de productos vendidos",
                ]

                return resultado
    ```

**Flujo de uso**

1. **Preparar el Dataframe:** Utilizar una query que tenga las siguientes columnas:`product_id , product_name, quantity, total_price, customer_id, customer_name, employee_id, employee_name`
2. **Elegir y aplicar la estrategia:**

    ```python
        strategy = TotalSalesByEmployee()
        report_df = strategy.generate_report(
            data=df,
            key="TotalVentas",
            ascending=False
        )
        print(report_df)
    ```

**Justificaci√≥n**

* Principio abierto/cerrado (OCP): Se puede agregar nuevas estrategias sin modificar las existentes
* Separaci√≥n de responsabilidades: cada clase encapsula un √∫nico algoritmo de agregaci√≥n y formato.
* Reutilizaci√≥n: el mismo constructor (ReportBuilder) y flujo puede generar tantos informes como estrategias se a√±adan.
* Flexibilidad: en tiempo de ejecuci√≥n se elige qu√© tipo de an√°lisis realizar (totales, promedios, conteos, etc.).
* Testabilidad: cada estrategia puede testearse de forma aislada, inyectando un DataFrame controlado y comprobando su salida.


### Patr√≥n Builder

El patr√≥n builder separa la construcci√≥n de un objeto complejo en mi caso, un conjunto de reportes y un reporte combinado de su representaci√≥n, permitiendo:

* Encadenar pasos de configuraci√≥n de forma legible.
* Evitar constructores con demasiados par√°metros.
* A√±adir nuevos pasos (por ejemplo filtros, exportaci√≥n, ordenamientos) sin romper el c√≥digo existente.

**Clase ReportBuilder**

La clase ReportBuilder tiene los siguientes atributos internos:

* `self.df`: El DataFrame de origen con los datos de ventas.
* `self._report_configs`: Lista de tuplas con cada estrategia de informe.
* `self.combined_sort_key` y `self.combined_sort_ascending`: Definen c√≥mo ordenar el reporte combinado al final (por ejemplo "Nombre Apellido Vendedor").


#### M√©todos encadenables

- `set_dataframe(df: pd.DataFrame)`: Establece el DataFrame base donde buscan las estrategias.
- `set_combined_sorting(key: str, ascending: bool) ‚Üí self`: Configura la columna y sentido de orden para todos los reportes
- `add_report(strategy: ReportStrategy) ‚Üí self`: A√±ade una estrategia (Strategy)
- `build_all() ‚Üí Dict[str, pd.DataFrame]`: Genera todos los reportes individuales seg√∫n las estrategias cargadas, y luego construye un `CombinedReport` uniendo con merge todos los resultados.
    - Este m√©todo itera en cada estrategia cargada en `_report_configs`, invocando el m√©todo `generate_report`, utilizando siempre las mismas claves de sentido y ordenamiento.

    ```python
    report = strategy.generate_report(
        self.df,
        key=self.combined_sort_key,
        ascending=self.combined_sort_ascending,
        )
    ```
    - guarda cada iteraci√≥n en el diccionario de resultados, bajo el nombre de la clase de la estrategia:` result[name] = report`
    - Hace un merge progresivo de todos los elementos de result en base al id del vendedor.
    - por ultimo llama al m√©todo interno `_clean_combined_df()` para fusionar o renombrar columnas duplicadas de "Nombre Apellido Vendedor" y aplicar el ordenamiento final.
    - Devuelve un diccionario con cada reporte m√°s el reporte combinado.

**Ejemplo de uso:**

```python
    builder = ReportBuilder()

        reports = (
            builder.set_dataframe(df_sales)
            .set_combined_sorting("EmployeeName", True)
            .add_report(TotalSalesByEmployee())
            .add_report(AverageSalesByEmployee())
            .add_report(ProductSalesByEmployee())
            .build_all()
        )
```
**Justificaci√≥n**

* Construcci√≥n fluida: el cliente no necesita conocer el detalle interno de c√≥mo se unen o limpian los reportes, s√≥lo encadena pasos.
* Abierto/Cerrado (OCP): para agregar un nuevo tipo de reporte o un paso extra (p. ej. exportar a Excel), basta con a√±adir un nuevo m√©todo al builder o pasar otra estrategia, sin tocar el flujo existente.
* Separaci√≥n de configuraci√≥n y ejecuci√≥n: primero se define qu√© se quiere obtener (datos, estrategias, orden), luego se ejecuta todo en build_all().
* Legibilidad: el c√≥digo se lee como un peque√±o ‚Äúpipeline‚Äù declarativo.

> Nota: combinar Strategy con Builder permite un dise√±o declarativo y fluido, donde s√≥lo cambia la configuraci√≥n de estrategias para obtener distintos reportes sin tocar la l√≥gica interna de cada una.

**Decisi√≥n de dise√±o**

**Elecci√≥n de implementaci√≥n de reportes centrados en Empleados**

Al abordar el an√°lisis solicitado por la empresa, opt√© por enfocar los reportes avanzados en el desempe√±o de los empleados/vendedores y no en los clientes.

Esta decisi√≥n se basa en los siguientes fundamentos:

* Relevancia para la toma de decisiones: El an√°lisis del rendimiento de los empleados es esencial para la direcci√≥n comercial, ya que permite identificar a los mejores vendedores, detectar √°reas de mejora y dise√±ar estrategias de incentivos y capacitaci√≥n.
* Mayor claridad y trazabilidad de los datos: Los datos de ventas por empleado suelen ser m√°s robustos y estables para la comparaci√≥n a lo largo del tiempo, y presentan relaciones uno-a-muchos bien definidas, lo que garantiza calidad y confiabilidad en los reportes.
* Facilidad para consultas SQL avanzadas: La estructura de la base de datos favorece la generaci√≥n de m√©tricas agregadas, rankings y comparativas por empleado, permitiendo responder r√°pidamente preguntas estrat√©gicas sin ambig√ºedades de interpretaci√≥n.
* Escalabilidad: Este enfoque no impide que en futuras iteraciones se realicen reportes por cliente, producto o cualquier otro eje; al contrario, sienta una base s√≥lida y extensible para an√°lisis futuros.


### Consultas desde Python

La clase de conexi√≥n expone un m√©todo para ejecutar consultas SQL simples directamente desde Python.

```python
def execute_query(self, query: str, params: dict = None) -> pd.DataFrame:
        try:
            with self.engine.connect() as connection:
                result = connection.execute(text(query), params)
                return pd.DataFrame(result.fetchall(), columns=result.keys())
        except Exception as e:
            raise RuntimeError(f"Error al ejecutar la consulta: {str(e)}")

```

**Funcionamiento:**

El m√©todo recibe una cadena SQL y par√°metros opcionales. Ejecuta la consulta usando SQLAlchemy. 

Los resultados se devuelven formateados como un DataFrame de Pandas. Esto facilita el an√°lisis, visualizaci√≥n y procesamiento de los datos dentro del entorno Python.

**Ventajas:**

* Integraci√≥n directa con todo el ecosistema de an√°lisis de datos en Python.
* Facilidad de uso para usuarios menos experimentados (por ejemplo, analistas que no quieren lidiar con SQLAlchemy "crudo").


### Pruebas unitarias:

#### Sobre patrones de dise√±o:

La cobertura de pruebas unitarias se dise√±√≥ espec√≠ficamente para validar el correcto funcionamiento y la integraci√≥n de los patrones de dise√±o implementados en el sistema. 

**Prueba de Singleton**

**Objetivo:**

Asegurarse de que la clase DBConnection cumpla el patr√≥n Singleton, es decir, que todas las instancias creadas apunten realmente al mismo objeto, compartiendo engine y sesi√≥n.

```python
def test_singleton_instance():
    db1 = DBConnection()
    db2 = DBConnection()
    assert db1 is db2
    assert db1.engine is db2.engine
    assert db1.Session is db2.Session
```

**Justificaci√≥n:**

Si este test falla, existe riesgo de conexiones duplicadas o inconsistentes, lo que podr√≠a provocar errores dif√≠ciles de rastrear en sistemas m√°s grandes.

**Pruebas de Strategy, Factory y Builder**

**a) Strategy**

Los tests de strategy se centran en comprobar que cada estrategia concreta de reporte (por ejemplo, ventas totales por empleado, promedio de ventas, productos vendidos) produce resultados correctos y coherentes seg√∫n la l√≥gica que encapsula. \
 Se valida:

* Que los reportes tengan la estructura esperada (columnas).
* Que no est√©n vac√≠os.
* Que contengan la cantidad correcta de filas seg√∫n los datos de entrada.
* Que el orden de los datos sea correcto, si corresponde.

**b) Factory**

* El patr√≥n Factory, aplicado en las clases SalesSummary y CustomerLocationInfo, centraliza y unifica la construcci√≥n de objetos complejos a partir de datos tabulares (por ejemplo, filas de un DataFrame de pandas).
* Los test verifican que el patr√≥n Factory est√© a modelos de dominio y garantizan que la construcci√≥n de objetos sea segura, homog√©nea 

**c) Builder**

Los tests sobre Builder buscan asegurarse de que es posible componer y encadenar estrategias para construir reportes complejos o agregados.

Se verifica:
* Que el builder puede recibir varias estrategias.
* Que los informes generados est√°n correctamente formateados y contienen datos.
* Que los reportes combinados cumplen con los criterios de ordenamiento y formato.


#### Pruebas unitarias sobre el ORM y relaciones de entidades

Adem√°s de los tests sobre patrones de dise√±o, el sistema incluye un conjunto de pruebas unitarias dedicadas a verificar la correcta integraci√≥n entre las clases Python y las tablas de la base de datos, as√≠ como el mapeo de relaciones (uno a muchos, muchos a uno, etc.) utilizando SQLAlchemy.

**Justificaci√≥n**

Si bien la informaci√≥n provista y mapeada por el ORM no se utiliza en esta etapa:

* Validan que el mapeo ORM respete el modelo relacional: Al trabajar con una base de datos ya existente, es fundamental asegurarse de que cada clase refleja fielmente la tabla correspondiente y que las relaciones entre entidades (por ejemplo, cada venta tiene un cliente, producto y empleado asociados) funcionan correctamente.
* Detectan problemas de integridad y errores de configuraci√≥n:
* Estos tests permiten identificar r√°pidamente errores en la declaraci√≥n de relaciones (ForeignKey, relationship, etc.) o desincronizaciones entre el modelo Python y la base real.
* Aportan robustez a la arquitectura: As√≠ como los patrones de dise√±o aseguran la escalabilidad del c√≥digo, estos tests garantizan la calidad y estabilidad del acceso a datos, minimizando sorpresas a medida que el sistema crece.

**Tipos de pruebas implementadas:**

1. **Test parametrizado de consulta de entidades** (archivo test_entidades.py)
    1. Valida que cada clase modelo est√° correctamente enlazada con su tabla y que las consultas b√°sicas (query.first()) funcionan sin errores.
2. **Tests de relaciones entre entidades** (archivo test_entidades.py)
    2. Clientes y su ciudad: Verifica que un cliente tenga asignada una ciudad v√°lida.
    3. Empleados, ciudad y pa√≠s: Verifica la relaci√≥n encadenada empleado -> ciudad -> pa√≠s.
    4. Categor√≠a y productos: Comprueba que la relaci√≥n de categor√≠a a productos (y viceversa) existe y es funcional. 
    5. Venta y sus v√≠nculos:Se asegura de que cada venta est√© correctamente enlazada a un cliente, producto y empleado.
    6. **Valida **que las relaciones de clave for√°nea y los accesos por atributo funcionan correctamente en el modelo ORM.


### Seguridad de Credenciales

**1. Archivo .env**

Las credenciales de acceso a la base de datos (usuario, password, host, nombre de la base) se almacenan en un archivo .env y se accede a ellas usando la librer√≠a `python-dotenv`.

Esto evita exponer datos sensibles en el c√≥digo fuente y permite una configuraci√≥n flexible para diferentes entornos (desarrollo, testing, producci√≥n, etc).

**2. Protecci√≥n en el repositorio**

El archivo `.env` est√° listado en el `.gitignore`, de modo que nunca se sube al repositorio. As√≠, las credenciales permanecen seguras, evitando filtraciones accidentales en plataformas p√∫blicas.

### Integraci√≥n Final en Jupyter Notebook

Se incluy√≥ un Jupyter Notebook de integraci√≥n que permite:

* Verificar la conexi√≥n exitosa a la base de datos.
* Ejecutar y visualizar resultados de queries como DataFrames.
* Mostrar el uso del patr√≥n Singleton (y cualquier otro patr√≥n de dise√±o implementado).
* Ejecutar pruebas unitarias directamente desde el notebook para dejar evidencia del correcto funcionamiento.

Esto permite no solo verificar el funcionamiento de cada componente, sino tambi√©n dejar evidencia replicable de todo el flujo de trabajo, facilitando tanto la evaluaci√≥n acad√©mica como la adopci√≥n por otros equipos de desarrollo.


# **Tercer Avance**
## Objetivo

El sistema ya es funcional, pero ahora debes garantizar que sea eficiente y capaz de operar con agilidad frente al crecimiento del volumen de datos.
Tu desaf√≠o es optimizar las consultas y automatizar procesos clave mediante la creaci√≥n de objetos avanzados en SQL.
As√≠, el sistema no solo ser√° robusto, sino tambi√©n estrat√©gico: capaz de generar reportes √∫tiles en tiempo real y facilitar decisiones informadas en la gesti√≥n del negocio.

## Entregables:

### Entregables realizados:

**Crea al menos dos queries usando**
- [x] CTE (Common Table Expressions)
- [x] Funciones ventana (ROW_NUMBER(), RANK(), etc.)
- [x] Ejecuta estas consultas desde Python (por ejemplo, con SQLAlchemy o pymysql).

**Objetos SQL**
- [x] Crea al menos dos objetos SQL, como:  Funci√≥n, Trigger, Procedimiento, almacenado, Vista, √çndice
- [x] Ejec√∫talos desde Python para demostrar su funcionamiento.

**Integraci√≥n en Notebook**
- [x] Incluye todas las ejecuciones en el notebook del Avance 2.
- [x] Los resultados est√©n visibles.
- [x] Cada paso est√© documentado con justificaciones e interpretaciones.


## Desarrollo:

### Consultas utilizando CTE y funciones ventana
#### Conocer los productos m√°s vendidos por categor√≠a:

```sql
    with ranked_products as (
        select c.CategoryName, p.ProductName, sum(Quantity) as total_vendido,
        dense_rank() over (
        partition by c.CategoryName
        order by sum(s.Quantity) desc 
        ) as ds
        from products p join categories c on p.CategoryID = c.CategoryID
        join sales s on s.ProductID = p.ProductID
        group by c.CategoryName, p.ProductName
        order by c.categoryName, ds)
    select * from ranked_products
    where ds<= 1
    order by categoryname, ds;
```

Esta consulta obtiene el o los productos m√°s vendidos por cada categor√≠a.

Se utiliza una **CTE (Common Table Expression)** para calcular el total vendido de cada producto, y se aplica la funci√≥n de ventana `DENSE_RANK() `para asignar un ranking de ventas dentro de cada categor√≠a. Finalmente, se filtran aquellos productos que ocupan el primer lugar en ventas ("estrella") en cada categor√≠a, permitiendo detectar empates si los hubiera..

**Justificaci√≥n**

Conocer el producto m√°s vendido por categor√≠a permite identificar cu√°les son los productos clave ("estrella") en cada segmento del cat√°logo de productos de la empresa. Esta informaci√≥n es fundamental para tomar decisiones comerciales estrat√©gicas, como focalizar acciones de marketing, gestionar el stock de manera m√°s eficiente o identificar oportunidades para promociones espec√≠ficas.

Adem√°s, permite anticipar riesgos de concentraci√≥n de ventas y detectar tendencias dentro de cada categor√≠a.

**Decisi√≥n t√©cnica**

En este caso decid√≠ utilizar la funci√≥n ventana `dense_rank()` en vez de `row_number()` o `rank()` porque en algunos casos pueden existir empates en la cantidad m√°xima vendida. De esta forma, si hay dos o m√°s productos que comparten el primer puesto dentro de una categor√≠a, todos ser√°n identificados como productos l√≠deres, evitando perder informaci√≥n relevante sobre el desempe√±o de los productos.


#### Porcentaje de participaci√≥n de productos en ventas

```sql
with ventas_por_categoria as (
    select
        c.CategoryID, c.CategoryName, p.ProductID, p.ProductName, SUM(s.TotalPrice) AS TotalFacturado
    from sales s
    join products p ON s.ProductID = p.ProductID
    join categories c ON p.CategoryID = c.CategoryID
    group by c.CategoryID, c.CategoryName, p.ProductID, p.ProductName
),
totales_categoria as (
    select
        CategoryID,
        SUM(TotalFacturado) AS TotalCategoria
    from ventas_por_categoria
    group by CategoryID
),
total_general_ventas as (
    select SUM(TotalFacturado) AS GranTotal from ventas_por_categoria
)
select
    v.CategoryName, v.ProductName, v.TotalFacturado, t.TotalCategoria, g.GranTotal,
    ROUND(100 * v.TotalFacturado / t.TotalCategoria, 2) AS PorcentajeEnCategoria,
    ROUND(100 * v.TotalFacturado / g.GranTotal, 2) AS PorcentajeEnTotal
from ventas_por_categoria v
join totales_categoria t ON v.CategoryID = t.CategoryID
join total_general_ventas g
order by v.CategoryName, PorcentajeEnCategoria DESC;
```


**Descripcion:**

Esta consulta calcula el total facturado por cada producto y determina su porcentaje de participaci√≥n tanto dentro de su categor√≠a como en el total general de ventas de la empresa.

Utilic√© para su c√°lculo varias CTE para:

1. Agregar el total facturado por producto y categor√≠a
2. Calcular el subtotal facturado por categor√≠a
3. Obtener el total global de ventas

Luego en el select final muestro estos valores junto con el porcentaje que representa cada producto tanto en su categor√≠a como en el total general

**Justificaci√≥n**

Conocer el peso relativo de cada producto en su categor√≠a y en el total de ventas es fundamental para la gesti√≥n estrat√©gica de portafolios de productos.

Esta informaci√≥n permite:

1. Detectar productos l√≠deres y de bajo rendimiento dentro de cada categor√≠a.
2. Identificar riesgos de concentraci√≥n excesiva de ventas en pocos productos.
3. Tomar decisiones informadas sobre inventarios, promociones, discontinuidad o refuerzo de productos.
4. Visualizar si los productos estrella de cada categor√≠a tambi√©n tienen impacto relevante en el total de la empresa, o si su importancia es solo a nivel de nicho.

**Decisi√≥n t√©cnica**

Opt√© por una soluci√≥n basada en CTE encadenadas para mejorar la legibilidad y modularidad del SQL.

* La CTE principal (`ventas_por_categoria`) realiza la agregaci√≥n de ventas por producto y categor√≠a.
* `totales_categoria`calcula los subtotales por categor√≠a y permite, mediante un JOIN, relacionar cada producto con el total de su categor√≠a para calcular su porcentaje.
* `total_general_ventas ` calcula el total global, que se incorpora a cada fila mediante un JOIN (al ser una sola fila) para que todos los productos puedan calcular su participaci√≥n sobre el total de la empresa sin replicar l√≥gica ni subconsultas en el SELECT final.


### Objetos SQL

#### Utilizaci√≥n de Stored Procedure para an√°lisis de participaci√≥n por producto

```sql
create procedure sp_porcentaje_producto_total(in v_cat_id int)
begin
	-- 1. ventas de todos los productos para calcular el total general
	with ventas_todas_categorias as (
		select
			c.CategoryID, c.CategoryName, p.ProductID, p.ProductName, SUM(s.TotalPrice) AS TotalFacturado
		from sales s
		join products p ON s.ProductID = p.ProductID
		join categories c ON p.CategoryID = c.CategoryID
		group by c.CategoryID, c.CategoryName, p.ProductID, p.ProductName
	),
    -- 2. filtramos las categorias que llega por parametro
    totales_por_categoria as(
		select * from ventas_todas_categorias
        where CategoryID = v_cat_id
    ),
    -- 3. calculamos los totales por la categoria
	totales_categoria as (
		select CategoryID, SUM(TotalFacturado) as TotalCategoria
        from totales_por_categoria
        group by categoryID
	),
    -- 4. calculamos el total general de ventas de todos los productos
	total_general_ventas as (
		select SUM(TotalFacturado) AS GranTotal from ventas_todas_categorias
	)
    -- usamos todo lo anterior para sacar informacion por producto
	select
		v.CategoryID, v.CategoryName, v.ProductName, v.TotalFacturado, t.TotalCategoria, g.GranTotal,
		ROUND(100 * v.TotalFacturado / t.TotalCategoria, 2) AS PorcentajeEnCategoria,
		ROUND(100 * v.TotalFacturado / g.GranTotal, 2) AS PorcentajeEnTotal
	from totales_por_categoria v
	join totales_categoria t ON v.CategoryID = t.CategoryID
	join total_general_ventas g
	order by v.CategoryName, PorcentajeEnCategoria DESC;
end
```


**Descripci√≥n**

Este procedimiento almacenado reutiliza parte de la l√≥gica de la secci√≥n anterior en el desarrollo de ‚ÄúPorcentaje de participaci√≥n de productos en ventas‚Äù, solamente que quise obtener el porcentaje de participaci√≥n de productos pero de alguna categor√≠a en particular.

- Tuve que rearmar la l√≥gica para agregar el filtro que llega desde la variable de entrada `v_cat_id`.
- Por eso separo primero la ejecuci√≥n del c√°lculo de ventas de todas las categor√≠as, y luego uso ese resultado para filtrar.
- El c√°lculo que queda es bastante similar a la l√≥gica de la CTE realizada en la secci√≥n anterior.

**Justificaci√≥n**

El uso de un procedimiento almacenado permite:

* Reutilizaci√≥n: encapsular l√≥gica compleja reutilizable en diferentes contextos anal√≠ticos o sistemas externos (por ejemplo, reportes autom√°ticos o dashboards).
* Parametrizaci√≥n: realizar el an√°lisis para distintas categor√≠as de forma din√°mica sin duplicar c√≥digo SQL.
* Seguridad y mantenimiento: ocultar detalles internos de la l√≥gica SQL, facilitando el mantenimiento y control de cambios desde el backend.

Adem√°s, el enfoque centrado en el an√°lisis porcentual permite a la empresa conocer el peso relativo de cada producto en su categor√≠a y en el total de ventas.

**Como crear el Stored Procedure desde Jupiter Notebook**

Para llamar al sp, se utilizo la clase `DBConnection` que ya ten√≠amos, y dentro de una celda de la notebook usar los siguientes comandos: 

```python
## Stored Procedure
from sqlalchemy import text
from src.db.database import DBConnection

db = DBConnection()
engine = db.engine

create_sp_sql = """
create procedure sp_porcentaje_producto_total(in v_cat_id int)
‚Äì ac√° va el codigo del stored procedure
"""

with engine.begin() as conn:
    # Si ya exist√≠a, lo borramos
    conn.execute(text("DROP PROCEDURE IF EXISTS sp_porcentaje_producto_total;"))
    # Ahora creamos la nueva versi√≥n
    conn.execute(text(create_sp_sql))

print("‚úÖ Stored procedure creado satisfactoriamente.")
```

**Para llamar al Stored Procedure**

Para llamar al sp, tuve que modificar la clase DBConnection agregando un m√©todo que me permitiera llamar stored procedures:

```python
def call_procedure(self, name: str, args: list = None) -> pd.DataFrame:
        """
        Ejecuta un stored procedure y devuelve el √∫ltimo result set como DataFrame.
        """
        raw = self.engine.raw_connection()
        try:
            cursor = raw.cursor()
            cursor.callproc(name, args or [])
            rows, cols = [], []
            for rs in cursor.stored_results():
                rows = rs.fetchall()
                cols = rs.column_names
            return pd.DataFrame(rows, columns=cols)
        finally:
            cursor.close()
            raw.close()
```

> üí° Nota t√©cnica:
>El error MySQLInterfaceError: Commands out of sync; you can't run this command now ocurre cuando se ejecuta un stored procedure y no se  consumen todos los result sets devueltos antes de cerrar la conexi√≥n.
> Por eso es fundamental consumir todos los resultados usando stored_results() y no el flujo normal de SQLAlchemy.

**Porque se produjo este error:**

Ocurre espec√≠ficamente cuando se ejecuta un `CALL nombre_procedimiento(...) ` y:


* El procedimiento devuelve uno o m√°s result sets (conjuntos de filas).
* No se consumen todos los resultados completamente antes de cerrar o reutilizar la conexi√≥n.

Cuando esto pasa, el conector queda en un estado inconsistente, ya que espera que todos los resultados hayan sido le√≠dos antes de permitir cualquier otro comando, incluyendo el rollback() que SQLAlchemy intenta hacer autom√°ticamente al salir del contexto with connection:.

pod√≠a llamar usando varios comandos al sp desde jupyter notebook, lo que me pareci√≥ bastante engorroso. por ello decid√≠ agregar el m√©todo para poder ejecutar sp sin problemas.

Tambi√©n agregue un procedimiento para llamar vistas:

```python
def query_view(
        self, view_name: str, where: str = None, params: dict = None
    ) -> pd.DataFrame:
        """
        Hace un SELECT * desde una vista (o tabla), opcionalmente filtrando.
        """
        sql = f"SELECT * FROM {view_name}"
        if where:
            sql += f" WHERE {where}"
        # Usa execute_query para todo el trabajo
        return self.execute_query(sql, params)
```

Para separar responsabilidades.

**Uso del m√©todo**

```python
## Llamamos al stored procedure
category_id = 1  # Cambia este valor seg√∫n la categor√≠a que quieras consultar
df_porcentajes = db.call_procedure("sp_porcentaje_producto_total", [category_id])
df_porcentajes
```


### Creaci√≥n de una vista

Vista: `vw_resumen_ventas_producto`:

```sql
create or replace view vw_resumen_ventas_producto AS
select
    p.ProductID,
    p.ProductName,
    c.CategoryName,
    ROUND(AVG(s.TotalPrice / NULLIF(s.Quantity, 0)), 2) AS PrecioUnitarioPromedio,
    SUM(s.Quantity) AS TotalUnidadesVendidas,
    SUM(s.TotalPrice) AS TotalFacturado,
    ROUND(SUM(s.TotalPrice) / NULLIF(SUM(s.Quantity), 0), 2) AS TicketPromedio
from sales s
join products p ON s.ProductID = p.ProductID
join categories c ON p.CategoryID = c.CategoryID
group by p.ProductID, p.ProductName, c.CategoryName
```


**Descripci√≥n**

Esta vista resume el rendimiento de cada producto en t√©rminos de ventas, brindando una perspectiva integral de su comportamiento comercial. Para cada producto muestra:

* Nombre del producto y categor√≠a
* Precio unitario promedio (√∫til si hubo promociones o descuentos)
* Cantidad total vendida
* Total facturado
* Ticket promedio por unidad vendida

Esto permite identificar r√°pidamente productos de alto impacto, bajo rendimiento, o variaciones significativas en el precio de venta.

**Justificaci√≥n**

Esta vista permite analizar r√°pidamente c√≥mo se desempe√±a cada producto en t√©rminos de ventas, sin necesidad de escribir consultas SQL complejas cada vez.

Al centralizar esta informaci√≥n en una vista:

* Se ahorra tiempo para futuros an√°lisis, ya que los datos est√°n listos para usarse.
* Se pueden detectar productos destacados (por ventas o facturaci√≥n) de forma inmediata.
* Se identifican productos con bajo rendimiento, que podr√≠an necesitar promociones o ajustes de precio.

Ayuda a entender si los productos se venden en gran volumen pero con bajo ticket, o viceversa.

**Decisi√≥n T√©cnica**

La facilidad de la implementaci√≥n de una vista, me llev√≥ a elegir este tipo de estructura. Adem√°s:

* Reduce la repetici√≥n de l√≥gica SQL compleja en an√°lisis posteriores.
* Puede ser consumida f√°cilmente desde Python o herramientas de BI, sin tener que conocer la l√≥gica interna de agregaci√≥n.
* Mejora la legibilidad y modularidad del modelo de datos, separando los datos operacionales (sales, products) de las vistas anal√≠ticas.

## Optimizaci√≥n y an√°lisis de rendimiento: √≠ndices

Ejemplo de √≠ndice y su impacto en el rendimiento

`CREATE INDEX idx_products_name ON products(ProductName)`;

**¬øQu√© hace este √≠ndice?**

Este comando crea un √≠ndice no √∫nico sobre la columna ProductName de la tabla products. El √≠ndice es una estructura (habitualmente un √°rbol B+) que almacena los valores de la columna ordenados y permite b√∫squedas r√°pidas.

**¬øC√≥mo optimiza el rendimiento?**

Sin este √≠ndice, cuando se ejecuta una consulta como:

```sql
    SELECT * FROM products WHERE ProductName = 'Caf√© molido';
```

el motor de base de datos debe recorrer toda la tabla (full table scan) para buscar coincidencias, lo cual es ineficiente si hay muchos registros.

Con el √≠ndice `idx_products_name`, MySQL puede localizar las filas deseadas de forma mucho m√°s eficiente, consultando primero el √≠ndice y luego recuperando los datos completos. El tiempo de b√∫squeda disminuye considerablemente, pasando de O(n) a O(log n).

Casos en los que ayuda:

Consultas de b√∫squeda exacta por nombre de producto:

```sql
SELECT * FROM products WHERE ProductName = 'Caf√© molido';
```

Consultas con comodines
```sql
SELECT * FROM products WHERE ProductName LIKE 'Caf%';
```

**Resumen:**

El √≠ndice sobre ProductName acelera de manera significativa las b√∫squedas, filtrados y ordenamientos que involucran esa columna, especialmente en tablas grandes.

Esto mejora el rendimiento de reportes, filtros y b√∫squedas en los sistemas que consumen la base de datos, brindando una mejor experiencia de usuario y menor carga sobre el servidor.


## üë©‚Äçüíª Autor

Proyecto desarrollado por Veronica Valdez como parte del Proyecto Final del Curso Data Engineering